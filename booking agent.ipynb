{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc86f556-f573-41cb-889e-0189178d450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries.\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f63139-fb7f-48ed-bfc3-5642341088bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama is running fine: True\n"
     ]
    }
   ],
   "source": [
    "# Checker function if ollama is running fine or not.\n",
    "def check_ollama(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_ollama(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running.\")\n",
    "\n",
    "print(f\"Ollama is running fine: {ollama_running}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec048cb-cd1c-4816-ac13-73f1ed5d59e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the LLMs which will be used for our use-case.\n",
    "def create_llm():\n",
    "  tool_llm = ChatOllama(\n",
    "          model=\"llama3-groq-tool-use\",\n",
    "          temperature=0,\n",
    "  )\n",
    "\n",
    "  response_llm = ChatOllama(\n",
    "          model=\"llama3.1:8b\",\n",
    "          temperature=0.5,\n",
    "  )\n",
    "  return tool_llm, response_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfdd7034-20ef-4567-9eb9-efa420c9fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy function to check if payment was successful\n",
    "def payment_done():\n",
    "    return True\n",
    "# Function which will be called if tool calling happens.\n",
    "@tool\n",
    "def book_room(name, contact_number, check_in_date, check_out_date, room_type)-> str:\n",
    "    \"\"\"Book a hotel's room on behalf of the user.\"\"\"\n",
    "    if(payment_done()):\n",
    "        # update the DB that a room is booked.\n",
    "        return f\"Thanks {name}. Your {room_type} room has been booked and details will be shared to your contact number: {contact_number}.\"\n",
    "    return \"Payment was not successful. Room wasn't booked.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a80d8e8-af2a-4412-903e-35088adc23cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the system prompt and basic flow of how query will be taken.\n",
    "def chat(query, tool_llm, response_llm):\n",
    "    messages = [HumanMessage(query)]\n",
    "    ai_msg = tool_llm.invoke([SystemMessage(\n",
    "                               content=\"\"\"You are an AI assistant for The Lalit Hotel. \n",
    "                                            There are five types of rooms available there:\n",
    "                                            - Deluxe Rooms\n",
    "                                            - Premier Rooms\n",
    "                                            - Executive Club Rooms\n",
    "                                            - Executive Suites\n",
    "                                            - Luxury Suites\n",
    "                                            - Presidential Suite\n",
    "                                            - The Lalit Legacy Suite\n",
    "                                        Your primary functions are:\n",
    "                                        Book rooms using the available booking tool\n",
    "                                        Answer general questions about the hotel\n",
    "                                        When booking rooms:\n",
    "                                            Use the \"book_room\" function to check availability and make reservations\n",
    "                                            Confirm details like dates, room type, and number of guests\n",
    "                                            Provide booking confirmation numbers\n",
    "                                        For general inquiries (You are also provided with all the information related to hotel before check that also):\n",
    "                                            Answer questions about amenities, services, policies, and local attractions\n",
    "                                            If you don't have specific information, politely say so and offer to connect the guest with hotel staff\n",
    "                                            Always be polite, professional, and helpful. If you need more information to assist a guest, ask clarifying questions.\n",
    "                                        \"\"\"\n",
    "                            )]\n",
    "                          + messages)\n",
    "    \n",
    "    messages.append(ai_msg)\n",
    "    \n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        selected_tool = {\"book_room\": book_room}[tool_call[\"name\"].lower()]\n",
    "        tool_msg = selected_tool.invoke(tool_call)\n",
    "        messages.append(tool_msg)\n",
    "        \n",
    "    system_message = f\"\"\"You are a secondary language model to help the guests of THE LALIT HOTEL and responsible for reviewing the response \n",
    "    generated by the primary model and finalizing the output based on the query and the tools invoked.\n",
    "    There are five types of rooms available there:\n",
    "                                            - Deluxe Rooms\n",
    "                                            - Premier Rooms\n",
    "                                            - Executive Club Rooms\n",
    "                                            - Executive Suites\n",
    "                                            - Luxury Suites\n",
    "                                            - Presidential Suite\n",
    "                                            - The Lalit Legacy Suite\n",
    "    Suggest these rooms to the user.\n",
    "    Instructions:\n",
    "\n",
    "    You will receive a query and a response generated by the first LLM.\n",
    "    Your task is to review the response in the context of the original query and the actions \n",
    "    performed and provide a final, coherent response.\n",
    "    If the first LLM invoked tools related to booking of rooms, ensure that the response accurately reflects \n",
    "    the results of those tool invocations.\n",
    "    \n",
    "    If the user's query is a generic question or greeting (e.g., \"Hello\", \"How are you?\", \"Whats up?\"), respond in a polite, \n",
    "    friendly, and conversational manner without using any tools.\n",
    "    Ensure that the final response is clear, polite, and aligned with the user's expectations.\n",
    "    Avoid stating that tools are inaccessible or unavailable unless explicitly required by the query.\n",
    "    Ensure that you return a response that is understandable and appropriate for the user's request.\n",
    "    Your response will be shown to the user, so DON'T PROVIDE GIBBERISH IN THE RESULT.\n",
    "    \"\"\"\n",
    "    \n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_message),\n",
    "    MessagesPlaceholder(variable_name=\"conversation\")\n",
    "    ])\n",
    "\n",
    "    formatted_messages = chat_prompt.format_messages(\n",
    "    conversation=messages  \n",
    "    )\n",
    "\n",
    "    response = response_llm.invoke(formatted_messages)\n",
    "\n",
    "    if ai_msg.tool_calls!=[]:\n",
    "        print(\"------------------------------------------------------------------\")\n",
    "        print(\"Tool was called with these arguments:\")\n",
    "        print(ai_msg.tool_calls)\n",
    "        print(\"------------------------------------------------------------------\")\n",
    "    \n",
    "    if response.content==\"\":\n",
    "      print(\"Final response:\", ai_msg.content)\n",
    "    \n",
    "    else:\n",
    "      print(\"Final response:\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "899a156a-4b53-4be1-b323-746e1c17a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the conversation with assistant.\n",
    "def start_llm(tool_llm, response_llm):\n",
    "    query = str(input(\"Query: \"))\n",
    "    if(query==\"bye\"):\n",
    "        return \"Alright, bye.\"\n",
    "    start = time.time()\n",
    "    chat(query = query, tool_llm = tool_llm, response_llm = response_llm)\n",
    "    end = time.time()\n",
    "    print(f\"Time taken to respond to this query: {end-start}.\")\n",
    "    start_llm(tool_llm = tool_llm, response_llm = response_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e00bc2ef-3b68-4389-868c-8aa5304e28ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [book_room]\n",
    "tool_llm, response_llm = create_llm()\n",
    "tool_llm = tool_llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbc1d0c-036c-497c-811a-3d63e03296de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  book a deluxe suite, my name is sarthak and my contact number is 432513, i'll stay from 7th march to 10th march'25.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Tool was called with these arguments:\n",
      "[{'name': 'book_room', 'args': {'check_in_date': '2025-03-07', 'check_out_date': '2025-03-10', 'contact_number': 432513, 'name': 'Sarthak', 'room_type': 'Deluxe Suite'}, 'id': '91739030-7f7e-4b52-8068-a5cd4c541aa2', 'type': 'tool_call'}]\n",
      "------------------------------------------------------------------\n",
      "Final response: Based on the query, I have invoked the \"book_room\" tool with the required parameters - check-in date (7th March '25), check-out date (10th March '25), contact number (432513), name (Sarthak) and room type (Deluxe Suite). The response is clear and concise, providing confirmation of the booking.\n",
      "Time taken to respond to this query: 53.145819902420044.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  hello, how are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final response:  We have a lovely hotel here at The Lalit, with various rooms and suites to suit your needs. Are you looking for some recommendations or information about our accommodations?\n",
      "Time taken to respond to this query: 1.3176093101501465.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Query:  how many types of rooms are there in your hotel?\n"
     ]
    }
   ],
   "source": [
    "start_llm(tool_llm, response_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07666308-ce3b-4ae6-918b-96b9e1713010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# book a deluxe suite, my name is sarthak and my contact number is 432513, i'll stay from 7th march to 10th march'25."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
